{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EvalPrediction\n)\nfrom sklearn.metrics import f1_score, roc_auc_score, hamming_loss\n\n# Detect device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\U0001F5A5️  Using device: {device}\")\n\n# Load dataset\ndataset = load_dataset(\"rntc/mimic-icd-visit\")\n\n# Extract unique ICD codes from all splits\nall_codes = []\nfor split in ['train', 'validation', 'test']:\n    all_codes.extend(code for example in dataset[split] for code in example['icd_code'])\n\nunique_codes = sorted(set(all_codes))\nNUM_ICD_CODES = len(unique_codes)\ncode_to_index = {code: idx for idx, code in enumerate(unique_codes)}\n\n# Encode labels\ndef encode_labels(example):\n    vec = [0] * NUM_ICD_CODES\n    for code in example['icd_code']:\n        vec[code_to_index[code]] = 1\n    example['labels'] = vec\n    return example\n\ndataset = dataset.map(encode_labels)\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n\ndef tokenize_function(example):\n    return tokenizer(\n        example[\"cleaned_text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512\n    )\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\ntokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"emilyalsentzer/Bio_ClinicalBERT\",\n    num_labels=NUM_ICD_CODES,\n    problem_type=\"multi_label_classification\"\n)\nmodel.to(device)\n\n# Get predictions function\ndef get_preds(model, dataset):\n    model.eval()\n    loader = torch.utils.data.DataLoader(dataset, batch_size=4)\n    preds, labels = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            output = model(input_ids, attention_mask=attention_mask)\n            logits = torch.sigmoid(output.logits).cpu().numpy()\n            preds.append(logits)\n            labels.append(batch['labels'].numpy())\n    return np.vstack(preds), np.vstack(labels)\n\n# Save predictions from pretrained model\npre_probs, true_labels = get_preds(model, tokenized_datasets['validation'])\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"micro_f1\",\n    fp16=True if torch.cuda.is_available() else False,\n    logging_dir=\"./logs\",\n)\n\n# Metrics function\ndef compute_metrics(eval_pred: EvalPrediction):\n    logits, labels = eval_pred\n    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n    preds = (probs > 0.5).astype(int)\n    return {\n        \"micro_f1\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n        \"macro_f1\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n        \"hamming_loss\": hamming_loss(labels, preds),\n        \"roc_auc\": roc_auc_score(labels, probs, average=\"macro\")\n    }\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    compute_metrics=compute_metrics,\n)\n\n# Train\ntrainer.train()\n\n# Save fine-tuned model\ntrainer.save_model(\"./best_bio_clinicalbert_icd_model\")\ntokenizer.save_pretrained(\"./best_bio_clinicalbert_icd_model\")\n\n# Evaluate fine-tuned model\nft_probs, _ = get_preds(trainer.model, tokenized_datasets['validation'])\n\n# Evaluation function\ndef evaluate(true, probs):\n    preds = (probs > 0.5).astype(int)\n    return {\n        \"micro_f1\": f1_score(true, preds, average=\"micro\"),\n        \"macro_f1\": f1_score(true, preds, average=\"macro\"),\n        \"hamming_loss\": hamming_loss(true, preds),\n        \"roc_auc\": roc_auc_score(true, probs, average=\"macro\"),\n    }\n\npre_metrics = evaluate(true_labels, pre_probs)\nft_metrics = evaluate(true_labels, ft_probs)\n\n# Plot comparison\nlabels = list(pre_metrics.keys())\npre_vals = [pre_metrics[l] for l in labels]\nft_vals = [ft_metrics[l] for l in labels]\n\nx = np.arange(len(labels))\nwidth = 0.35\n\nplt.figure(figsize=(10, 6))\nplt.bar(x - width/2, pre_vals, width, label='Pretrained')\nplt.bar(x + width/2, ft_vals, width, label='Fine-tuned')\n\nplt.ylabel(\"Score\")\nplt.title(\"Model Performance: Pretrained vs Fine-tuned\")\nplt.xticks(x, labels)\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}